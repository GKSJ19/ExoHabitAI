# -*- coding: utf-8 -*-
"""ModelTraining.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Bm9eTZiESsNUxyq3rM5xghTfHhA5clo5
"""

import pandas as pd
import numpy as np

df = pd.read_csv("Final_preprocessed_1.csv")

print(df.shape)
print(df.columns)

df = df.select_dtypes(include=[np.number])

# Replace infinite values with NaN
df.replace([np.inf, -np.inf], np.nan, inplace=True)

# Fill missing values with median
df = df.fillna(df.median())

print("Total NaNs left:", df.isna().sum().sum())

X = df.drop(['target'], axis=1)
y = df['target']

print("Class Distribution:")
print(y.value_counts())

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,
    random_state=42,
    stratify=y
)

print("Train size:", X_train.shape)
print("Test size :", X_test.shape)

from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression

log_pipe = Pipeline([
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler()),
    ('model', LogisticRegression(max_iter=1000))
])

log_pipe.fit(X_train, y_train)

from sklearn.metrics import classification_report, confusion_matrix

y_pred = log_pipe.predict(X_test)

print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))

from sklearn.ensemble import RandomForestClassifier

rf_pipe = Pipeline([
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler()),
    ('rf', RandomForestClassifier(n_estimators=200, random_state=42))
])

rf_pipe.fit(X_train, y_train)

y_pred_rf = rf_pipe.predict(X_test)

print(confusion_matrix(y_test, y_pred_rf))
print(classification_report(y_test, y_pred_rf))

from imblearn.over_sampling import SMOTE

!pip install imbalanced-learn

from imblearn.pipeline import Pipeline as ImbPipeline

balanced_pipe = ImbPipeline([
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler()),
    ('smote', SMOTE(random_state=42)),
    ('model', LogisticRegression(max_iter=1000))
])

balanced_pipe.fit(X_train, y_train)

from sklearn.metrics import classification_report, confusion_matrix

y_pred = balanced_pipe.predict(X_test)

print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))

rf_balanced = ImbPipeline([
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler()),
    ('smote', SMOTE(random_state=42)),
    ('rf', RandomForestClassifier(n_estimators=200, random_state=42))
])

rf_balanced.fit(X_train, y_train)

y_pred_rf_bal = rf_balanced.predict(X_test)

print(confusion_matrix(y_test, y_pred_rf_bal))
print(classification_report(y_test, y_pred_rf_bal))

"""**XG Boost Classifier**"""

!pip install xgboost

from xgboost import XGBClassifier

xgb_pipe = Pipeline([
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler()),
    ('xgb', XGBClassifier(
        n_estimators=200,
        learning_rate=0.1,
        max_depth=6,
        random_state=42
    ))
])

xgb_pipe.fit(X_train, y_train)

y_pred_xgb = xgb_pipe.predict(X_test)

print("----- XGBOOST RESULTS -----")
print(confusion_matrix(y_test, y_pred_xgb))
print(classification_report(y_test, y_pred_xgb))



from imblearn.pipeline import Pipeline as ImbPipeline
from imblearn.over_sampling import SMOTE

xgb_balanced = ImbPipeline([
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler()),
    ('smote', SMOTE(random_state=42)),
    ('xgb', XGBClassifier(
        n_estimators=200,
        learning_rate=0.1,
        max_depth=6,
        random_state=42
    ))
])

xgb_balanced.fit(X_train, y_train)

y_pred_xgb_bal = xgb_balanced.predict(X_test)

print("----- XGBOOST + SMOTE RESULTS -----")
print(confusion_matrix(y_test, y_pred_xgb_bal))
print(classification_report(y_test, y_pred_xgb_bal))

from sklearn.metrics import accuracy_score, f1_score

models = {
    "Logistic": log_pipe,
    "Random Forest": rf_pipe,
    "Logistic + SMOTE": balanced_pipe,
    "RF + SMOTE": rf_balanced,
    "XGBoost": xgb_pipe,
    "XGBoost + SMOTE": xgb_balanced
}

for name, model in models.items():
    pred = model.predict(X_test)
    print(name)
    print("Accuracy:", accuracy_score(y_test, pred))
    print("F1 Score:", f1_score(y_test, pred))
    print("-" * 40)

import pandas as pd

importances = xgb_pipe.named_steps['xgb'].feature_importances_

feature_imp = pd.DataFrame({
    'Feature': X.columns,
    'Importance': importances
}).sort_values(by='Importance', ascending=False)

print("Top Important Features:")
print(feature_imp.head(10))

import matplotlib.pyplot as plt

plt.figure(figsize=(10,6))
plt.barh(feature_imp["Feature"][:10], feature_imp["Importance"][:10])
plt.title("Top 10 Important Features")
plt.xlabel("Importance Score")
plt.gca().invert_yaxis()
plt.show()

import joblib

joblib.dump(log_pipe, "logistic_model.pkl")

joblib.dump(log_pipe, "logistic_model.pkl")
joblib.dump(rf_pipe, "random_forest_model.pkl")
joblib.dump(balanced_pipe, "logistic_smote_model.pkl")
joblib.dump(xgb_pipe, "xgboost_model.pkl")
joblib.dump(xgb_balanced, "xgboost_smote_model.pkl")

joblib.dump(rf_balanced, "random_forest_smote_model1.pkl")

from sklearn.metrics import precision_recall_fscore_support
import pandas as pd

models = {
    "Logistic Regression": log_pipe,
    "Random Forest": rf_pipe,
    "Logistic + SMOTE": balanced_pipe,
    "Random Forest + SMOTE": rf_balanced,
    "XGBoost": xgb_pipe,
    "XGBoost + SMOTE": xgb_balanced
}

results = []

for name, model in models.items():
    y_pred = model.predict(X_test)

    precision, recall, f1, support = precision_recall_fscore_support(y_test, y_pred, average='binary')

    results.append({
        "Model": name,
        "Precision": precision,
        "Recall": recall,
        "F1 Score": f1,
        "Accuracy": accuracy_score(y_test, y_pred),
        "Support (Class 1)": support
    })

comparison_df = pd.DataFrame(results)

print("\n===== MODEL COMPARISON =====")
print(comparison_df)