{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "656f654a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, VotingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "\n",
    "# Ensure directory exists\n",
    "os.makedirs('models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0732a1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. LOAD DATA\n",
    "X_train = pd.read_csv('X_train_final.csv')\n",
    "y_train_reg = pd.read_csv('y_train_regression.csv').values.ravel()\n",
    "X_test = pd.read_csv('X_test_final.csv')\n",
    "y_test_cont = pd.read_csv('y_test_final.csv').values.ravel()\n",
    "y_test_bin = (y_test_cont > 0.75).astype(int) # Threshold for evaluation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3c6ed11",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [8660, 4355]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      4\u001b[39m xgb_param_grid = {\n\u001b[32m      5\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mn_estimators\u001b[39m\u001b[33m'\u001b[39m: [\u001b[32m100\u001b[39m, \u001b[32m200\u001b[39m],\n\u001b[32m      6\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mlearning_rate\u001b[39m\u001b[33m'\u001b[39m: [\u001b[32m0.05\u001b[39m, \u001b[32m0.1\u001b[39m],\n\u001b[32m      7\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmax_depth\u001b[39m\u001b[33m'\u001b[39m: [\u001b[32m3\u001b[39m, \u001b[32m5\u001b[39m, \u001b[32m7\u001b[39m]\n\u001b[32m      8\u001b[39m }\n\u001b[32m      9\u001b[39m xgb_grid = GridSearchCV(xgb_base, xgb_param_grid, cv=\u001b[32m3\u001b[39m, scoring=\u001b[33m'\u001b[39m\u001b[33mr2\u001b[39m\u001b[33m'\u001b[39m, n_jobs=-\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mxgb_grid\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_reg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m best_xgb = xgb_grid.best_estimator_\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Random Forest: Focus on Depth and Estimators\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\D\\Infoysys-internship\\ExoHabitAI\\.venv\\Lib\\site-packages\\sklearn\\base.py:1336\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1329\u001b[39m     estimator._validate_params()\n\u001b[32m   1331\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1332\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1333\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1334\u001b[39m     )\n\u001b[32m   1335\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1336\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\D\\Infoysys-internship\\ExoHabitAI\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:957\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    954\u001b[39m estimator = \u001b[38;5;28mself\u001b[39m.estimator\n\u001b[32m    955\u001b[39m scorers, refit_metric = \u001b[38;5;28mself\u001b[39m._get_scorers()\n\u001b[32m--> \u001b[39m\u001b[32m957\u001b[39m X, y = \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    958\u001b[39m params = _check_method_params(X, params=params)\n\u001b[32m    960\u001b[39m routed_params = \u001b[38;5;28mself\u001b[39m._get_routed_params_for_fit(params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\D\\Infoysys-internship\\ExoHabitAI\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:521\u001b[39m, in \u001b[36mindexable\u001b[39m\u001b[34m(*iterables)\u001b[39m\n\u001b[32m    491\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[32m    492\u001b[39m \n\u001b[32m    493\u001b[39m \u001b[33;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    517\u001b[39m \u001b[33;03m[[1, 2, 3], array([2, 3, 4]), None, <...Sparse...dtype 'int64'...shape (3, 1)>]\u001b[39;00m\n\u001b[32m    518\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    520\u001b[39m result = [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[32m--> \u001b[39m\u001b[32m521\u001b[39m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    522\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\D\\Infoysys-internship\\ExoHabitAI\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:464\u001b[39m, in \u001b[36mcheck_consistent_length\u001b[39m\u001b[34m(*arrays)\u001b[39m\n\u001b[32m    462\u001b[39m lengths = [_num_samples(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m arrays \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[32m    463\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(lengths)) > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    465\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    466\u001b[39m         % [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[32m    467\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Found input variables with inconsistent numbers of samples: [8660, 4355]"
     ]
    }
   ],
   "source": [
    "# 2. TUNING THE BASE MODELS\n",
    "# XGBoost: Focus on Learning Rate and Depth\n",
    "xgb_base = XGBRegressor(random_state=42, objective='reg:squarederror')\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "xgb_grid = GridSearchCV(xgb_base, xgb_param_grid, cv=3, scoring='r2', n_jobs=-1)\n",
    "xgb_grid.fit(X_train, y_train_reg)\n",
    "best_xgb = xgb_grid.best_estimator_\n",
    "\n",
    "# Random Forest: Focus on Depth and Estimators\n",
    "rf_base = RandomForestRegressor(random_state=42)\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "rf_grid = GridSearchCV(rf_base, rf_param_grid, cv=3, scoring='r2', n_jobs=-1)\n",
    "rf_grid.fit(X_train, y_train_reg)\n",
    "best_rf = rf_grid.best_estimator_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea5d177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. CONSTRUCT THE WEIGHTED ENSEMBLE\n",
    "# Giving 70% weight to XGBoost based on our baseline observations\n",
    "ensemble = VotingRegressor(\n",
    "    estimators=[('xgb', best_xgb), ('rf', best_rf)],\n",
    "    weights=[0.7, 0.3]\n",
    ")\n",
    "\n",
    "# Create final pipeline\n",
    "final_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('ensemble', ensemble)\n",
    "])\n",
    "\n",
    "final_pipeline.fit(X_train, y_train_reg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bc0285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. EVALUATION & RANKING\n",
    "y_pred_cont = final_pipeline.predict(X_test)\n",
    "y_pred_bin = (y_pred_cont > 0.75).astype(int) # Optimized threshold\n",
    "\n",
    "# Mandatory Metrics\n",
    "print(\"\\n--- Final Ensemble Regression Results ---\")\n",
    "print(f\"Mean Absolute Error (MAE): {mean_absolute_error(y_test_cont, y_pred_cont):.4f}\")\n",
    "print(f\"R-squared Score (R2): {r2_score(y_test_cont, y_pred_cont):.4f}\")\n",
    "\n",
    "print(\"\\n--- Final Ensemble Classification Performance ---\")\n",
    "print(classification_report(y_test_bin, y_pred_bin))\n",
    "\n",
    "# 5. FEATURE IMPORTANCE (From Random Forest component)\n",
    "# Required by mentor document\n",
    "plt.figure(figsize=(10, 6))\n",
    "importances = best_rf.feature_importances_\n",
    "indices = np.argsort(importances)[-15:] # Top 15 features\n",
    "plt.barh(range(len(indices)), importances[indices], align='center')\n",
    "plt.yticks(range(len(indices)), [X_train.columns[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Top 15 Contributions to Habitability Prediction')\n",
    "plt.show()\n",
    "\n",
    "# 6. EXPORT FINAL RANKING\n",
    "# Ranking all planets in the test set\n",
    "results_df = pd.DataFrame({\n",
    "    'habitability_score': y_pred_cont\n",
    "})\n",
    "results_df.to_csv('data/processed/habitability_ranked.csv', index=False)\n",
    "joblib.dump(final_pipeline, 'models/ensemble_habitability_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
